{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(2024)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#!gdown 1eIrRyAqckN6zCjPb9VS-2rw7Bup7YhsA\n",
    "#!pip install PyWavelets\n",
    "\n",
    "data = pd.read_pickle('FE_hometask_data_v3.pickle')\n",
    "\n",
    "X_train = np.array([x[0] for x in data['train'].values()])\n",
    "y_train = np.array([x[1] for x in data['train'].values()])\n",
    "\n",
    "X_val = np.array([x[0] for x in data['val'].values()])\n",
    "y_val = np.array([x[1] for x in data['val'].values()])\n",
    "\n",
    "def efficient_eval(train_features, val_features):\n",
    "  model = DecisionTreeClassifier(max_depth=20, random_state=2024).fit(train_features, y_train)\n",
    "  preds = model.predict(val_features)\n",
    "  return roc_auc_score(y_val, preds)\n",
    "\n",
    "def super_duper_efficient_eval(train_features, val_features):\n",
    "  model = DecisionTreeClassifier(max_depth=4, random_state=2024).fit(train_features, y_train)\n",
    "  preds = model.predict(val_features)\n",
    "  return roc_auc_score(y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Transformations\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pywt\n",
    "import numpy as np\n",
    "\n",
    "def normalized_to_range(raw_data, feature_set):\n",
    "    ranges = np.ptp(raw_data, axis=(1,2))\n",
    "\n",
    "    return np.array([features / range for (features, range) in zip(feature_set, ranges)])\n",
    "\n",
    "def generate_polynomial_features(data, degree, include_bias=True):\n",
    "    poly = PolynomialFeatures(degree, include_bias=include_bias)\n",
    "    poly_features = poly.fit_transform(data)\n",
    "    return poly_features\n",
    "\n",
    "def compute_wavelet_transform_features(data, wavelet='db1', level=2):\n",
    "    features = []\n",
    "    for sample in data:\n",
    "        coeffs = [pywt.wavedec(sample[:, i], wavelet, level=level) for i in range(sample.shape[1])]\n",
    "        flattened_coeffs = [item for sublist in coeffs for item in sublist]  # Flatten the list of coefficients\n",
    "        feature_vector = np.concatenate([np.ravel(coeff) for coeff in flattened_coeffs])  # Flatten each array and concatenate\n",
    "        features.append(feature_vector)\n",
    "    return np.array(features)\n",
    "\n",
    "def compute_fourier_transform_features(data, num_coefficients=4):\n",
    "    features = []\n",
    "    for sample in data:\n",
    "        fourier = np.fft.fft(sample, axis=0)\n",
    "        magnitude = np.abs(fourier)\n",
    "        # Keep only the first 'num_coefficients' coefficients for each channel\n",
    "        truncated_magnitude = magnitude[:num_coefficients, :].flatten()\n",
    "        features.append(truncated_magnitude)\n",
    "    return np.array(features)\n",
    "\n",
    "def generate_all_features(data):\n",
    "    global pca\n",
    "\n",
    "    features = {}\n",
    "    features['mean'] = np.mean(data, axis=1)\n",
    "    features['std'] = np.std(data, axis=1)\n",
    "    features['min'] = np.min(data, axis=1)\n",
    "    features['max'] = np.max(data, axis=1)\n",
    "    features['median'] = np.median(data, axis=1)\n",
    "    features['range'] = features['max'] - features['min']\n",
    "    features['variance'] = np.var(data, axis=1)\n",
    "    features['skewness'] = skew(data, axis=1)\n",
    "    features['kurtosis'] = kurtosis(data, axis=1)\n",
    "    features['ft'] = compute_fourier_transform_features(data, 4)\n",
    "    features['wavelet'] = compute_wavelet_transform_features(data)\n",
    "    features['mad'] = np.array([np.mean(np.absolute(x - np.mean(x, axis=0)), axis=0) for x in data]) # https://stackoverflow.com/questions/8930370/where-can-i-find-mad-mean-absolute-deviation-in-scipy\n",
    "    features['normean'] = (features['mean'] - features['min']) / (features['max'] - features['min'])\n",
    "    features['normstd'] = normalized_to_range(data, features['std'])\n",
    "    features['normad'] = normalized_to_range(data, features['mad'])\n",
    "    features['diff2'] = np.diff(data, axis=1)[:, :, 2]\n",
    "\n",
    "    # if data is X_train:\n",
    "    #     pca = PCA(n_components=15)\n",
    "    #     features['wavelet'] = pca.fit_transform(compute_wavelet_transform_features(X_train))\n",
    "    # else:\n",
    "    #     features['wavelet'] = pca.transform(compute_wavelet_transform_features(data))\n",
    "\n",
    "\n",
    "    return features\n",
    "\n",
    "def construct_features(features_dict: dict, include_stats_list: list, polinom_degree: int = 1):\n",
    "    #takes a dict of generated features (coming from generate_all_features()), keys to include in the feature set (order doesn't matter), and the degree to generate polinom\n",
    "    selected_features = []\n",
    "    feature_names = features_dict.keys()\n",
    "\n",
    "    if (isinstance(include_stats_list[0], bool)): #bruteforces pass a bool list\n",
    "        for include, name in zip(include_stats_list, feature_names):\n",
    "            if include:\n",
    "                selected_features.append(features_dict[name])\n",
    "    elif (isinstance(include_stats_list[0], str)):\n",
    "        for name in include_stats_list:\n",
    "            selected_features.append(features_dict[name])\n",
    "\n",
    "    return generate_polynomial_features(np.hstack(selected_features), polinom_degree)\n",
    "\n",
    "train_features = generate_all_features(X_train)\n",
    "val_features = generate_all_features(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -> std\n",
      "2 -> min\n",
      "4 -> max\n",
      "8 -> range\n",
      "16 -> skewness\n",
      "32 -> normstd\n",
      "64 -> normad\n",
      "[-1, 0.6954005694086474, 0.5103300577029422, 0.6954005694086474, 0.5119646161572147, 0.6954005694086474, 0.5122801943883742, 0.6954005694086474, 0.7832778710291368, 0.776843201585121, 0.7832778710291368, 0.776843201585121, 0.7832778710291368, 0.776843201585121, 0.7832778710291368, 0.776843201585121, 0.7928214257101488, 0.7908566336889044, 0.7928214257101488, 0.7908566336889044, 0.7928214257101488, 0.7908566336889044, 0.7928214257101488, 0.7908566336889044, 0.8074660142762511, 0.8220070384692796, 0.8074660142762511, 0.8220070384692796, 0.8074660142762511, 0.8220070384692796, 0.8074660142762511, 0.8220070384692796, 0.793452582172468, 0.7873432611834867, 0.793452582172468, 0.7873432611834867, 0.793452582172468, 0.7873432611834867, 0.793452582172468, 0.7873432611834867, 0.8115734163932632, 0.8124165867136679, 0.8115734163932632, 0.8124165867136679, 0.8115734163932632, 0.8124165867136679, 0.8115734163932632, 0.8115734163932632, 0.8216543333873952, 0.8352437377750074, 0.8216543333873952, 0.8352437377750074, 0.8216543333873952, 0.8352437377750074, 0.8216543333873952, 0.8352437377750074, 0.8384561873850778, 0.8470999044472104, 0.8384561873850778, 0.8470999044472104, 0.8384561873850778, 0.8470999044472104, 0.8384561873850778, 0.8470999044472104, 0.7721241834535396, 0.7320418400067219, 0.7721241834535396, 0.7320418400067219, 0.7721241834535396, 0.7320418400067219, 0.7721241834535396, 0.7320418400067219, 0.7869094632434407, 0.7877526335638455, 0.7869094632434407, 0.7877526335638455, 0.7869094632434407, 0.7877526335638455, 0.7869094632434407, 0.7874888375192227, 0.8145933925929978, 0.8017709507795662, 0.8145933925929978, 0.8017709507795662, 0.8145933925929978, 0.8017709507795662, 0.8145933925929978, 0.8017709507795662, 0.8282296940552095, 0.8347112605738247, 0.8282296940552095, 0.8347112605738247, 0.8282296940552095, 0.8347112605738247, 0.8282296940552095, 0.8347112605738247, 0.8062134715754876, 0.7992609802661018, 0.8062134715754876, 0.7992609802661018, 0.8062134715754876, 0.7992609802661018, 0.8062134715754876, 0.7992609802661018, 0.8303918445987273, 0.8312350149191319, 0.8303918445987273, 0.8312350149191319, 0.8303918445987273, 0.8312350149191319, 0.8312350149191319, 0.8312350149191319, 0.8223890542227885, 0.8351919555884705, 0.8223890542227885, 0.8351919555884705, 0.8223890542227885, 0.8351919555884705, 0.8223890542227885, 0.8351919555884705, 0.852738300645421, 0.872187885313204, 0.852738300645421, 0.872187885313204, 0.852738300645421, 0.872187885313204, 0.852738300645421]\n",
      "0.872187885313204: std range skewness normstd normad \n",
      "0.872187885313204: std min range skewness normstd normad \n",
      "0.872187885313204: std max range skewness normstd normad \n",
      "0.852738300645421: range skewness normstd normad \n",
      "0.852738300645421: min range skewness normstd normad \n",
      "0.852738300645421: max range skewness normstd normad \n",
      "0.852738300645421: min max range skewness normstd normad \n",
      "0.8470999044472104: std range skewness normstd \n",
      "0.8470999044472104: std min range skewness normstd \n",
      "0.8470999044472104: std max range skewness normstd \n"
     ]
    }
   ],
   "source": [
    "# @title Bruteforce\n",
    "\n",
    "transforms_to_try = ['std', 'normad', 'normstd', 'range', 'skewness', 'min', 'max']\n",
    "eval_function = super_duper_efficient_eval\n",
    "polinom_degree = 2\n",
    "display_topx = 10\n",
    "_train_features = train_features\n",
    "_val_features = val_features\n",
    "\n",
    "\n",
    "indices = []\n",
    "blst = [False]*len(_train_features)\n",
    "generated_scores = [-1]\n",
    "ordered_transforms_to_try = []\n",
    "for i, key in enumerate(_train_features.keys()):\n",
    "    if key in transforms_to_try:\n",
    "        indices.append(i)\n",
    "        ordered_transforms_to_try.append(key)\n",
    "\n",
    "for i in range(1, (2**len(transforms_to_try))-1):\n",
    "    for j in range(7):\n",
    "        if (i >> j) & 1:\n",
    "            blst[indices[j]] = True\n",
    "\n",
    "    generated_scores.append(eval_function(\n",
    "        construct_features(_train_features, blst, polinom_degree),\n",
    "        construct_features(_val_features, blst, polinom_degree)\n",
    "    ))\n",
    "\n",
    "    for j in range(7):\n",
    "        if i >> j & 1:\n",
    "            blst[indices[j]] = False\n",
    "\n",
    "for i in range(len(transforms_to_try)):\n",
    "    print(2**i, \"->\", ordered_transforms_to_try[i])\n",
    "\n",
    "print(generated_scores)\n",
    "\n",
    "enumerated_arr = list(enumerate(generated_scores))\n",
    "# Sort the list based on the values in descending order\n",
    "sorted_arr = sorted(enumerated_arr, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i in range(display_topx):\n",
    "    print(f\"{sorted_arr[i][1]}: \", end = '')\n",
    "\n",
    "    for j in range(len(ordered_transforms_to_try)):\n",
    "        if (sorted_arr[i][0] >> j) & 1:\n",
    "            print(ordered_transforms_to_try[j], end = ' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.872187885313204"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Examples\n",
    "\n",
    "# best efficient (0.9410445150940189):\n",
    "efficient_eval(\n",
    "    construct_features(train_features, ['normstd', 'range', 'skewness', 'ft', 'normean'], 2),\n",
    "    construct_features(val_features, ['normstd', 'range', 'skewness', 'ft', 'normean'], 2)\n",
    ")\n",
    "# or:\n",
    "efficient_eval(\n",
    "    generate_polynomial_features(np.hstack((train_features['normstd'], train_features['range'], train_features['skewness'], train_features['ft'], train_features['normean'])), 2),\n",
    "    generate_polynomial_features(np.hstack((val_features['normstd'], val_features['range'], val_features['skewness'], val_features['ft'], val_features['normean'])), 2)\n",
    ")\n",
    "# or:\n",
    "def efficient_eval_transform(data):\n",
    "    return generate_polynomial_features(\n",
    "        data=np.concatenate(\n",
    "            (\n",
    "                normalized_to_range(data, np.std(data, axis=1)),\n",
    "                # range\n",
    "                np.ptp(data, axis=1),\n",
    "                skew(data, axis=1),\n",
    "                compute_fourier_transform_features(data, num_coefficients=4),\n",
    "                (np.mean(data, axis=1) - np.min(data, axis=1)) / (np.max(data, axis=1) - np.min(data, axis=1)),\n",
    "            ),\n",
    "            axis=1,\n",
    "        ),\n",
    "        degree=2,\n",
    "        include_bias=True,\n",
    "    )\n",
    "\n",
    "efficient_eval(\n",
    "    efficient_eval_transform(X_train),\n",
    "    efficient_eval_transform(X_val)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# best super_duper_efficient(0.872187885313204):\n",
    "super_duper_efficient_eval(\n",
    "    construct_features(train_features, ['std', 'normad', 'normstd', 'range', 'skewness'], 2),\n",
    "    construct_features(val_features, ['std', 'normad', 'normstd', 'range', 'skewness'], 2)\n",
    ")\n",
    "# or:\n",
    "super_duper_efficient_eval(\n",
    "    generate_polynomial_features(np.hstack((train_features['std'], train_features['normstd'], train_features['normad'], train_features['range'], train_features['skewness'])), 2),\n",
    "    generate_polynomial_features(np.hstack((val_features['std'], val_features['normstd'], val_features['normad'], val_features['range'], val_features['skewness'])), 2)\n",
    ")\n",
    "# or:\n",
    "def super_duper_efficient_eval_transform(data):\n",
    "    return generate_polynomial_features(\n",
    "        data=np.concatenate(\n",
    "            (\n",
    "                np.std(data, axis=1),\n",
    "                normalized_to_range(data, np.std(data, axis=1)),\n",
    "                normalized_to_range(data, np.array(np.array([np.mean(np.absolute(x - np.mean(x, axis=0)), axis=0) for x in data]))),\n",
    "                # range\n",
    "                np.ptp(data, axis=1),\n",
    "                skew(data, axis=1),\n",
    "            ),\n",
    "            axis=1,\n",
    "        ),\n",
    "        degree=2,\n",
    "        include_bias=False,\n",
    "    )\n",
    "super_duper_efficient_eval(\n",
    "    super_duper_efficient_eval_transform(X_train),\n",
    "    super_duper_efficient_eval_transform(X_val),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
